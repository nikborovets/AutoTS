#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ AutoTS —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TimeSeriesSplit.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from autots import AutoTS
from autots.data_loader import fetch_frame
# –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –≤ AutoTS —Ñ—É–Ω–∫—Ü–∏–∏,
# –Ω–æ –∏—Ö –º–æ–∂–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –æ—Ç–¥–µ–ª—å–Ω–æ –∏–∑ autots.evaluator.metrics
import logging
import os
import sys
import io
import datetime
from pathlib import Path
import matplotlib.pyplot as plt
from contextlib import contextmanager

from autots.viz import plot_history_forecast

@contextmanager
def capture_to_logging(logger):
    """
    –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ stdout –∏ stderr –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏—Ö –≤ –ª–æ–≥–≥–µ—Ä.
    """
    original_stdout = sys.stdout
    original_stderr = sys.stderr
    
    class LoggingWriter(io.TextIOBase):
        def __init__(self, logger, level):
            self.logger = logger
            self.level = level
            self.buffer = ''

        def write(self, string):
            # –ë—É—Ñ–µ—Ä–∏–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–æ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏
            self.buffer += string
            lines = self.buffer.split('\\n')
            for line in lines[:-1]:
                if line.strip():
                    self.logger.log(self.level, line.strip())
            self.buffer = lines[-1]
            return len(string)

        def flush(self):
            if self.buffer.strip():
                self.logger.log(self.level, self.buffer.strip())
            self.buffer = ''

    log_stdout = LoggingWriter(logger, logging.INFO)
    log_stderr = LoggingWriter(logger, logging.ERROR)

    sys.stdout = log_stdout
    sys.stderr = log_stderr
    try:
        yield
    finally:
        log_stdout.flush()
        log_stderr.flush()
        sys.stdout = original_stdout
        sys.stderr = original_stderr


def setup_logging():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª –∏ –≤ –∫–æ–Ω—Å–æ–ª—å."""
    log_dir = 'logs'
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # –ò–º—è –ª–æ–≥-—Ñ–∞–π–ª–∞ —Å –æ—Ç–º–µ—Ç–∫–æ–π –≤—Ä–µ–º–µ–Ω–∏, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ª–æ–≥–∏
    log_file = os.path.join(
        log_dir,
        f"autots_cv_run_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
    )
    
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
        
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.FileHandler(log_file),  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'a', —Ñ–∞–π–ª —É–Ω–∏–∫–∞–ª–µ–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            logging.StreamHandler()
        ]
    )
    logging.info("–°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞.")

def run_timeseries_cv(
    template_path='prometheus_autots_template_tuned.csv',
    n_splits=5,
    forecast_length=48,
    days=7,
    start_date="2025-04-27 18:00:00",
    end_date="2025-05-13 11:41:00"
):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –º–æ–¥–µ–ª–∏ AutoTS –Ω–∞ –æ—Å–Ω–æ–≤–µ —à–∞–±–ª–æ–Ω–∞.
    """
    if not os.path.exists(template_path):
        logging.error(f"‚ùå –®–∞–±–ª–æ–Ω –º–æ–¥–µ–ª–∏ '{template_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        logging.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ 'prometheus_autots_integration.py' –¥–ª—è –µ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è.")
        return

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logging.info("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ Prometheus...")
    df = fetch_frame(
        days=days,
        start_date=start_date,
        end_date=end_date,
        use_cache=True,
        verbose=False
    )
    df_clean = df.dropna(axis=1, thresh=len(df) * 0.7)
    logging.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_clean)} –∑–∞–ø–∏—Å–µ–π —Å {len(df_clean.columns)} –º–µ—Ç—Ä–∏–∫–∞–º–∏: {list(df_clean.columns)}")
    logging.info(f"üóìÔ∏è –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {df_clean.index.min()} - {df_clean.index.max()}")

    # 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ TimeSeriesSplit
    # –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (test_size) –¥–ª—è –∫–∞–∂–¥–æ–π —Å–∫–ª–∞–¥–∫–∏ —Ä–∞–≤–µ–Ω –≥–æ—Ä–∏–∑–æ–Ω—Ç—É –ø—Ä–æ–≥–Ω–æ–∑–∞.
    tscv = TimeSeriesSplit(n_splits=n_splits, test_size=forecast_length)
    logging.info(f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–µ–Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è TimeSeriesSplit —Å {n_splits} —Å–ø–ª–∏—Ç–∞–º–∏ –∏ —Ä–∞–∑–º–µ—Ä–æ–º —Ç–µ—Å—Ç–∞ {forecast_length}.")

    all_results = []
    
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø–æ–¥ –≥—Ä–∞—Ñ–∏–∫–∏
    plots_dir = Path("plots_cv")
    plots_dir.mkdir(exist_ok=True)

    # 3. –¶–∏–∫–ª –ø–æ —Å–ø–ª–∏—Ç–∞–º
    for i, (train_index, test_index) in enumerate(tscv.split(df_clean)):
        train_df = df_clean.iloc[train_index]
        test_df = df_clean.iloc[test_index]

        logging.info("\n" + "="*50)
        logging.info(f"üöÄ –°–ø–ª–∏—Ç {i + 1}/{n_splits}")
        logging.info(f"   –û–±—É—á–µ–Ω–∏–µ: {len(train_df)} —Ç–æ—á–µ–∫ ({train_df.index.min()} -> {train_df.index.max()})")
        logging.info(f"   –¢–µ—Å—Ç:     {len(test_df)} —Ç–æ—á–µ–∫ ({test_df.index.min()} -> {test_df.index.max()})")
        logging.info("="*50)

        # 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ AutoTS
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, –Ω–æ –±–µ–∑ –ø–æ–∏—Å–∫–∞ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (max_generations=0)
        model_config = {
            'forecast_length': forecast_length,
            'frequency': 'infer',
            'prediction_interval': 0.9,
            'max_generations': 0,  # –ù–µ –∏—â–µ–º –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω
            'num_validations': 0,  # –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, —Ç.–∫. –¥–µ–ª–∞–µ–º –≤–Ω–µ—à–Ω—é—é CV
            'ensemble': None,
            'n_jobs': 'auto',
            'verbose': 1,  # –î–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏
            'random_seed': 2024 + i, # –ú–µ–Ω—è–µ–º seed –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è, –µ—Å–ª–∏ –≤ –º–æ–¥–µ–ª—è—Ö –µ—Å—Ç—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
            'no_negatives': True,
        }
        
        model = AutoTS(**model_config)
        
        logging.info(f"üìÑ –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π –∏–∑ —à–∞–±–ª–æ–Ω–∞: {template_path}")
        model = model.import_template(template_path, method='only')
        
        # –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ AutoTS –≤—Å—ë-—Ç–∞–∫–∏ –ø–æ–ª–µ–∑–µ—Ç —Å–æ–±–∏—Ä–∞—Ç—å –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å
        model.ensemble_templates = pd.DataFrame()
        
        try:
            logging.info("üèãÔ∏è –û–±—É—á–∞—é –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
            with capture_to_logging(logging.getLogger()):
                model.fit(train_df, future_regressor=None)

            # —á–µ–∫–ø–æ–∏–Ω—Ç —à–∞–±–ª–æ–Ω–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
            model.export_template(str(plots_dir / f"template_split_{i+1}.csv"), models='best', n=50)

            logging.info("üîÆ –î–µ–ª–∞—é –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥...")
            with capture_to_logging(logging.getLogger()):
                prediction = model.predict(future_regressor=None)

            # 5. –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            logging.info("üìà –û—Ü–µ–Ω–∏–≤–∞—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞...")
            evaluation = prediction.evaluate(actual=test_df)
            score_df = evaluation.per_series_metrics
            score_df['split'] = i + 1
            all_results.append(score_df)
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–ø–ª–∏—Ç–µ {i+1}: {e}", exc_info=True)
            continue

        # 6. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ vs —Ñ–∞–∫—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Å–µ—Ä–∏–∏
        ts_stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        for col in prediction.forecast.columns:
            y_pred_series = prediction.forecast[col]
            y_true_series = test_df[col]
            # –ü–æ–∫–∞–∂–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –º–∏–Ω—É—Ç –∏—Å—Ç–æ—Ä–∏–∏ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –ø—Ä–æ–≥–Ω–æ–∑–∞
            hist_start = y_pred_series.index[0] - pd.Timedelta(minutes=30)
            history_series = train_df.loc[hist_start : y_pred_series.index[0], col]

            if 'prediction' in locals():
                plot_history_forecast(
                    history=history_series,
                    forecast=y_pred_series,
                    actual=y_true_series,
                    title=f"Fold {i + 1} ‚Äî {col}",
                    filename=str(plots_dir / f"cv_fold_{i + 1}_{col}_{ts_stamp}.png"),
                )

    # 6. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∏ –≤—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logging.info("\n" + "="*50)
    logging.info("üèÜ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏")
    logging.info("="*50)

    if not all_results:
        logging.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–ø–ª–∏—Ç–∞.")
        return

    final_results_df = pd.concat(all_results, ignore_index=False)
    
    # –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º —Å–ø–ª–∏—Ç–∞–º –¥–ª—è –∫–∞–∂–¥–æ–π —Å–µ—Ä–∏–∏
    avg_metrics = final_results_df.groupby(final_results_df.index).mean().drop('split', axis=1)
    std_metrics = final_results_df.groupby(final_results_df.index).std().drop('split', axis=1)

    logging.info("\n–°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —Å–µ—Ä–∏—è–º (AVG ¬± STD):\n")
    
    # –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å AVG ¬± STD
    for series_name in avg_metrics.index:
        logging.info(f"‚û°Ô∏è  {series_name}:")
        for metric in avg_metrics.columns:
            avg = avg_metrics.loc[series_name, metric]
            std = std_metrics.loc[series_name, metric]
            logging.info(f"    {metric:<10}: {avg:.2f} ¬± {std:.2f}")

    # –û–±—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Å–µ–º —Å–µ—Ä–∏—è–º –∏ —Å–ø–ª–∏—Ç–∞–º
    overall_avg = avg_metrics.mean()
    logging.info("\n" + "-"*30)
    logging.info("üìä –û–±—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Å–µ–º —Å–µ—Ä–∏—è–º:")
    logging.info(overall_avg.round(2).to_string())
    logging.info("-"*30)
    
    logging.info("\nüéâ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞."""
    setup_logging()
    
    try:
        run_timeseries_cv(
            template_path='prometheus_autots_template_tuned.csv',
            n_splits=5,
            forecast_length=48, # –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å test_size –≤ TimeSeriesSplit
            days=7,
            start_date="2025-04-27 18:00:00",
            end_date="2025-05-13 11:41:00"
        )
    except Exception as e:
        logging.error(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        raise

if __name__ == "__main__":
    main() 